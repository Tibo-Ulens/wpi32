//! # Assembler
//!
//! The assembler is responsible for converting a text file into a binary that
//! can be executed by the simulator <br>
//! This is achieved using the following steps:
//!  - Lexing: The [`Lexer`] converts the raw text of the input file into a series of abstracted
//!    [`Token`]s that more conveniently represent their underlying data
//!  - Parsing: The [`Parser`] converts the stream of [`Token`]s generated by the [`Lexer`] into a
//!    structured representation called an Abstract Syntax Tree (AST) (see [parse::ast])

#![warn(missing_docs)]
#![feature(let_chains)]
#![feature(assert_matches)]

#[macro_use]
extern crate log;

use std::fs::File;
use std::io::Read;
use std::path::Path;

pub mod error;
pub mod lex;
pub mod parse;

use error::Error;
use lex::{Lexer, Token};
use parse::Parser;

use crate::parse::Node;

/// Assemble a file at the given input path into a binary, and write it to the
/// file given by the output path
///
/// See the [module level documentation](self) for more info
pub fn assemble(input_path: &Path, _output_path: &Path) -> Result<(), Error> {
	let src_file = input_path.to_string_lossy().to_string();
	let mut file = File::open(input_path)?;
	let mut contents = String::new();
	file.read_to_string(&mut contents)?;

	info!("Lexing file {}", &src_file);
	let lexer = Lexer::new(&src_file, &contents);
	let tokens: Vec<Token> = lexer.into_iter().collect::<Result<Vec<Token>, Error>>()?;

	debug!("Lexemes for file {}:", &src_file);
	debug!("{}", tokens.iter().map(|t| t.to_string()).collect::<Vec<String>>().join("\n"));

	info!("Parsing file {}", &src_file);
	let mut parser = Parser::new(&src_file, &tokens);
	let ast_root = parser.parse()?;

	debug!("{}", Node::from(&ast_root));

	Ok(())
}
